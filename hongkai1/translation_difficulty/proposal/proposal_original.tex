%!TEX encoding = UTF-8 Unicode 
\documentclass[11pt]{article}
%\usepackage{CJKutf8}
\usepackage[english]{babel}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
%\usepackage{algorithmic}
\usepackage{enumerate}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{chngpage}

% New commands serve as shorthand for frequently used command combinations.
\newcommand{\ind}[1]{\mathbf{1}\left(#1\right)}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\E}{\mathbf{E}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\mH}{\mathcal{H}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

%%AL-COMMENTS insert title and name here
\title{Predicting Translation Difficulty for MT Systems}

\author{
	Junyi Jessy Li and Kai Hong\\
   University of Pennsylvania \\
   Philadelphia, PA 19104 \\
  	{\tt \{ljunyi, hongkai1\}@seas.upenn.edu}}

\begin{document}
\maketitle


\section{Problem Statement}
Machine Translation (MT), despite its many recent advances, still remains a hard problem. Translations produced by automatic systems suffer from problems such as information reordering, misalignments, mistranslations, etc. In this study, we propose to explore the question of how difficult a sentence is to translate automatically.

We propose to study this problem from two viewpoints. The first one is whether certain languages are intrinsically more difficult for MT. Intuitively some properties unique to certain languages poses problems for automatic systems. For example, Chinese and Romanian are well known for their zero anaphora \cite{zhao-ng:2007:EMNLP-CoNLL2007,mihuailua2011zero}; information expressed as individual words in one language may be morphologically expressed in another \cite{minkov-toutanova-suzuki:2007:ACLMain}; reorderings often must be explicitly handled \cite{Wang07chinesesyntactic}, and a single word in one language may be decomposed into several in another \cite{maja-compound}.

We also investigate whether certain properties in a sentence makes it difficult to translate. 
Length, for instance, is a natural indicator for how difficult for a human to translate a sentence \cite{mishra-bhattacharyya-carl:2013:Short}. 
We ask the question whether it is also the case for automatic systems. 
Other indicators we conjecture include the use of subordinations, structure and complexities of verb phrases and noun phrases, etc.

Through this study we hope to characterize difficulties that may lie ahead for MT systems, and we aim at quantitatively estimate such difficulties by developing a set of features for a machine learning framework.

\section{Related Work}
A handful of studies focus on 

\section{Datasets}
To investiagate sentece translation difficulty, we propose using the data from NAACL WSMT 2006 \cite{WMT:2006} and ACL WSMT 2007 \cite{WMT:2007} test set for our study. 
The test set in these two years include language pairs of English-German, English-French, English-Spanish and English-Czech (for WSMT 2007 only) in both directions. 
We choose these two years for the reason that they provide manual evaluation of fluency and adequency per sentence, apart from the BLEU score. 
If time permits, we would like to look into the intrinsically difficulty of more languages. The WSMT workshop of later years include Hungarian, Haitian Creole and Russian. 

\section{Approach and Evaluation}
\subsection{Objective Function and Evaluation}
The plan of this study is to investigate and collect a set of language dependent and independent factors of a sentence that are indicative of translation difficulty. 
One challenge of such an approach is the lack of a reliable sentence-level evaluation metric for translation hypothesis. 
%For analysis, a comparison can be carried out between scores of sentences that contains one or more factors vs those that do not. 
%One challenge of 
We conjecture that with more systems, the average of automatic scores or hudge evaluations would provide a partial but feasible solution this problem.
Thus, we look into the manual evaluation of fluency and adequency as the quality score of sentence, which takes the value between $1$ and $5$. 
The gold-standard difficulty for a sentence is thus the average of fluency and adequency of all MT systems, where higher score indicates easier sentence-pairs.
Similarly, the gold-standard difficulty between two languages take the average of manual evaluation scores among all systems
For the cases where manual evaluation is not available, we use the \emph{BLEU} score as gold-standard, similar to Birch et al. ~\shortcite{birch-osborne-koehn:2008:EMNLP,} and Koehn et al ~\shortcite{sys462}.

To demonstrate the effectiveness of those features, we will compute the Spearman Correlation between the features and the difficulty score.
To this end, we can also compute the goodness of fit for simple linear regression models using one feature. 
Since the final difficulty takes a value between $1$ and $5$, we regard our problem as a regression problem, which could be evaluated through Mean-square Error.
We can also compute the pariwise accurracy, predicting which sentence-pair (language-pair) is more difficult than the other. 

\subsection{Proposed Default and Baseline}
Since sentence length is one of the most crucial indicator of translation difficulty for human \cite{mishra-bhattacharyya-carl:2013:Short}, we regard it as our Default System.
Morphological complexity of the language pairs has long been recognized as one of the main factors influcing translation performance.
A simple alternative method of measuring morphological complexity is vocabulary size, which could form a strong baseline for language-pair prediction.

\bibliographystyle{acl}
\bibliography{references}
\end{document}